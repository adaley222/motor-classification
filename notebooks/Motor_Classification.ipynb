{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpWUMThnS+DmWo7AB4MKU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adaley222/motor-classification/blob/main/Motor_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4M6mms4Vial"
      },
      "source": [
        "# A Convolutional Neural Network to Classify EEG Motor Imagery\n",
        "## Author: Andrew Daley\n",
        "\n",
        "This notebook is based on the research done by Lun et. al. found in this paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7522466/, as well as many others.\n",
        "\n",
        "The purpose of the notebook is to use the Physionet MI-EEG dataset to train a convolutional neural network to classify motor-imagery events.\n",
        "\n",
        "What that means simply, is that we have a dataset where subjects were instructed to imagine themselves closing their right or left fist, but not actually closing them. The experimenters used EEG machines to pick up the brain-wave activity of those events.\n",
        "\n",
        "We can then use that EEG data to train a network to classify similar events in real-time. While this may seem trivial, the ability for a computer to recognize brain-wave events has wide-ranging uses for scenarios where someone is unable to interface with a phone or computer using their hands.\n",
        "\n",
        "This is a pet project. I think that Brain-Computer Interfaces are fascinating, and while the idea of a chip in your brain is little more than a meme today, I believe some version of a BCI will become ubiquitious within our lifetimes.\n",
        "\n",
        "Humor me as I explore the world of BCI, and learn a little about creating and training CNNs along the way. This is a work in progress, so if you come across this and see an error message below, please feel free to fix it for me =)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guc4dBcobTPD"
      },
      "source": [
        "First, we'll install the packages and libraries we need.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haEcrl2mijkp",
        "outputId": "4fc1d89c-1108-4034-986c-c60ec2c6e6b8"
      },
      "source": [
        "!pip install pyEDFlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyEDFlib\n",
            "  Downloading pyEDFlib-0.1.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pyEDFlib) (1.23.5)\n",
            "Installing collected packages: pyEDFlib\n",
            "Successfully installed pyEDFlib-0.1.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBkZ1H4EJ7D8",
        "outputId": "f9a800de-6433-4759-8239-5701f58fc251"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.2)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ftiGPPik5y"
      },
      "source": [
        "import os\n",
        "from urllib.error import HTTPError\n",
        "import numpy as np\n",
        "import pyedflib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import tensorflow as tf\n",
        "\n",
        "from mne import Epochs, pick_types, events_from_annotations\n",
        "from mne.channels import make_standard_montage\n",
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "from mne.datasets import eegbci\n",
        "from mne.decoding import CSP\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout, BatchNormalization, Activation, MaxPooling2D, Flatten\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juhwd1yYkViw"
      },
      "source": [
        "My first iteration used a library called pyEDFlib to load the data. I was able to sucessfully write functions to process the data and train the network using that library.\n",
        "\n",
        "However, after further research and learning from BCI professionals, I learned that a library called MNE is much more popular and provides much more powerful functionality for EEG pre-processing.\n",
        "\n",
        "I am in the process of re-writing everything using MNE. However, we will begin with the code I wrote for PyEDFlib. Unfortunately, PyEDFlib cannot read the edf files in their standard format. There is a header value in the files that causes the library to fail to load the file. I have gone and changed the files manually, locally on my machine, and have been uploading them to colab every session.\n",
        "\n",
        "This is an obvious problem with PyEDFlib, and one of the many reasons I am switching to MNE. However, walking through this pipeline gives us a good idea of how we need to engineer our data.\n",
        "\n",
        "We start by creating a \"master\". EDF signals and annotations (event labels) are separate. We need to combine the signal with the appropriate annoations into a single object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zag2FeaqmVVN"
      },
      "source": [
        "def create_master(edf, signal_length, time_length):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in an edf file and returns the dataset, as well as a master set\n",
        "\n",
        "    Assumes file is a standard 64 signal edf\n",
        "\n",
        "    removes last half second of file (which is 0 for my dataset)\n",
        "\n",
        "    This is designed for two-minute recordings. The function will currently not work properly if time_length is not set to 120. This is a TODO.\n",
        "\n",
        "    INPUT\n",
        "    edf: an edf file read in with pyedflib.EdfReader()\n",
        "    signal_length: length of signal (how many datapoints in each signal)\n",
        "    time_length: length of experiment in seconds\n",
        "\n",
        "    RETURNS\n",
        "    dataset: ndarray (signal_length x #_signals), represents the signal for each node\n",
        "    master_df: pandas dataframe (signal_length x (2 + #_signals)), with timestamp and annotation as first two columns\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    annotations = edf.readAnnotations()\n",
        "\n",
        "    # removes last 0.5 seconds from record (trailing 0s)\n",
        "    trunc_time = time_length - 0.5\n",
        "    trunc_length = int(signal_length - signal_length * (1 - trunc_time/time_length))\n",
        "\n",
        "    # creates a vector of time values by dividing up our time_length into signal_length parts\n",
        "    timeArray = np.array([round(x,5) for x in np.arange(0,trunc_time,time_length/signal_length)])\n",
        "    timeArray = timeArray.reshape(trunc_length,1)\n",
        "\n",
        "    # creates codeArray, which is a vector of length signal_length (same as timeArray)\n",
        "    # codeArray assigns the appropriate annotation at each point in timeArray\n",
        "    intervals = np.append(annotations[0],[124.5])\n",
        "    codes = annotations[2]\n",
        "    codeArray = []\n",
        "    counter = 1\n",
        "    for timeVal in timeArray:\n",
        "        if timeVal == 124.5:\n",
        "            break\n",
        "        elif timeVal / intervals[counter] == 1.0:\n",
        "            counter += 1\n",
        "\n",
        "        codeArray.append(codes[counter - 1])\n",
        "\n",
        "    invertCodeArray = np.array(codeArray).reshape(trunc_length,1)\n",
        "    numSignals = edf.signals_in_file\n",
        "    signal_labels = edf.getSignalLabels()\n",
        "    dataset = np.zeros((numSignals, edf.getNSamples()[0]))\n",
        "\n",
        "    # creates array of (signal_source, signal) i.e. (node 64, signal of that node)\n",
        "    # Then removes trailing 0 values\n",
        "    for signal in np.arange(numSignals):\n",
        "        dataset[signal, :] = edf.readSignal(signal)\n",
        "\n",
        "    num_trailing_0s = signal_length - trunc_length\n",
        "    dataset = dataset[:,:-num_trailing_0s].transpose()\n",
        "\n",
        "    # combine arrays into master_df\n",
        "    masterSet = np.concatenate((timeArray,invertCodeArray,dataset),axis=1)\n",
        "    master_df = pd.DataFrame(masterSet, columns = [\n",
        "                                         \"timestamp\",\n",
        "                                         \"label\",\n",
        "                                         \"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\",\"c10\",\"c11\",\"c12\",\"c13\",\"c14\",\"c15\",\"c16\",\"c17\",\"c18\",\"c19\",\"c20\",\"c21\",\"c22\",\"c23\",\"c24\",\"c25\",\"c26\",\"c27\",\"c28\",\"c29\",\"c30\",\"c31\",\"c32\",\"c33\",\"c34\",\"c35\",\"c36\",\"c37\",\"c38\",\"c39\",\"c40\",\"c41\",\"c42\",\"c43\",\"c44\",\"c45\",\"c46\",\"c47\",\"c48\",\"c49\",\"c50\",\"c51\",\"c52\",\"c53\",\"c54\",\"c56\",\"c57\",\"c58\",\"c59\",\"c60\",\"c61\",\"c62\",\"c63\",\"c64\",\"c65\"\n",
        "                              ])\n",
        "\n",
        "    return dataset, master_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBGffr4RllsR"
      },
      "source": [
        "Now that we have the master, we need to pull random samples from the master. This is where I deviate from the research papers into what I believe is a more valuable model.\n",
        "\n",
        "Real-time EEG data will be coming in rapidly, and will need to be sampled every fraction of a second to provide real-time output. Most research has used epoch style samples for training, which are not really how a BCI product would work in the real world.\n",
        "\n",
        "Therefore, I randomly sample the data to create a new dataset of random, quarter-second bits that will represent an actual quarter-second sample taken in real-time. These samples are then combined into the new training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MF3qxlwt6EW"
      },
      "source": [
        "def create_samples(eeg, sample_size, num_samples):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes in an eeg dataframe and returns a designated number of samples of length sample_size and their labels\n",
        "  These samples are random, but retain their time series order\n",
        "\n",
        "  INPUT\n",
        "  eeg: a pandas dataframe with label and channels as columns and time series indicies as rows\n",
        "  sample_size: length of samples to return\n",
        "  num_samples: number of samples to return\n",
        "\n",
        "  OUTPUT\n",
        "  samples: 2d numpy array with each  sample as a row\n",
        "    dimensions are (num_samples, number of channels)\n",
        "\n",
        "  labels: 1d numpy array with label for each sample\n",
        "    length(num_samples)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if sample_size > eeg.shape[0]:\n",
        "    print(\"sample_size must be less than length of eeg\")\n",
        "    return\n",
        "\n",
        "  samples = np.zeros((num_samples, sample_size, eeg.shape[1]-2))\n",
        "  labels = np.zeros(num_samples)\n",
        "\n",
        "  for i in range(num_samples):\n",
        "    start = np.random.randint(0, eeg.shape[0]-sample_size+1)\n",
        "    df_sample = eeg[start:start+sample_size]\n",
        "    sample = df_sample.drop(columns= [\"timestamp\", \"label\"]).to_numpy()\n",
        "\n",
        "    # we're currently using the max value as the label. We may want to return and try other methods (averages, etc.)\n",
        "    label = df_sample[\"label\"].value_counts().idxmax()\n",
        "    if label == \"T0\":\n",
        "      label = 0\n",
        "    elif label == \"T1\":\n",
        "      label = 1\n",
        "    elif label == \"T2\":\n",
        "      label = 2\n",
        "\n",
        "    samples[i] = sample\n",
        "    labels[i] = label\n",
        "\n",
        "  return samples, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg769YRzZz_3"
      },
      "source": [
        "# Create eeg dataframe from edf file\n",
        "dataset, master_df = create_master(S001R03, 20000, 125)\n",
        "\n",
        "sample_size = 160\n",
        "num_samples = 120\n",
        "\n",
        "# Sample each dataframe randomly in one second intervals\n",
        "samples, labels = create_samples(master_df, sample_size= sample_size, num_samples=num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGZHxPaVmmLp"
      },
      "source": [
        "Finally, I write a function to process an entire directory using the functions above, and create a final training set that is sampled from all edf files in a designated directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ8JmfGA3UkL"
      },
      "source": [
        "def process_dir(dir_name, num_samples, sample_size):\n",
        "\n",
        "  \"\"\"\n",
        "  Takes a directory of edf files, samples each using the create_samples function, and combines all samples into a master sample\n",
        "\n",
        "  INPUT:\n",
        "  dir_name: string, name of directory. Must be in cwd\n",
        "\n",
        "  OUTPUT:\n",
        "  master_sample: a numpy array of size (num_samples * train_dir_len, sample_size * train_dir_len, 64 * train_dir_len)\n",
        "  \"\"\"\n",
        "\n",
        "  train_dir_len = len([name for name in os.listdir(dir_name)])\n",
        "\n",
        "  master_sample = []\n",
        "  master_labels = []\n",
        "\n",
        "  for i, filename in enumerate(os.listdir(dir_name)):\n",
        "\n",
        "    edf = pyedflib.EdfReader(dir_name + \"/\" + filename)\n",
        "\n",
        "    dataset, master_df = create_master(edf, 20000, 125)\n",
        "\n",
        "    samples, labels = create_samples(master_df, sample_size = sample_size, num_samples = num_samples)\n",
        "\n",
        "    master_sample.append(samples)\n",
        "    master_labels.append(labels)\n",
        "\n",
        "  master_sample = np.array(master_sample)\n",
        "  master_sample = master_sample.reshape((train_dir_len * num_samples, sample_size, 64))\n",
        "\n",
        "  master_labels = np.array(master_labels)\n",
        "  master_labels = master_labels.reshape((train_dir_len * num_samples))\n",
        "\n",
        "  return master_sample, master_labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG04cIe63Zvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "ef4186c4-3eb9-402f-e7c0-ac304190f2aa",
        "collapsed": true
      },
      "source": [
        "master_sample, master_labels = process_dir(\"\",160,120)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'process_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-01da56fd5154>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'process_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Np6mLuvK_Dh"
      },
      "source": [
        "master_sample = master_sample.reshape((640,120,64,1))\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(master_sample, master_labels,\n",
        "                                               train_size = 0.8,\n",
        "                                               test_size = 0.2,\n",
        "                                               random_state = 24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqsnJ6YNnQ5f"
      },
      "source": [
        "Now that we have our final training dataset, we can begin building our CNN. Again, the network is based on the research paper cited above. The details of the network can be found in the docstring below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yobdSo5NpWt1"
      },
      "source": [
        "# One hot encode labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Convert to tf tensors\n",
        "x_train_tensor = tf.convert_to_tensor(x_train)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train)\n",
        "x_test_tensor = tf.convert_to_tensor(x_test)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMDeMWCIv7tB",
        "outputId": "a2913809-3783-4171-bc24-4df394cdf277"
      },
      "source": [
        "\"\"\"\n",
        "Here we  build our network. We'll use the following architecture:\n",
        "\n",
        "Dropout Rate: 50%\n",
        "Learning Rate: 1 × 10^−5\n",
        "\n",
        "L1 - Input Layer - num_files*sample size, sample_size, 64\n",
        "L2 - Convolution1\n",
        "    Activation\n",
        "    Dropout\n",
        "L3 - Convolution2\n",
        "    Batch normalization\n",
        "    Activation\n",
        "L4 - Max Pooling1\n",
        "L5 - Convolution3\n",
        "    Activation\n",
        "    Dropout\n",
        "L6 - Max Pooling2\n",
        "L7 - Convolution4\n",
        "    Batch normalization\n",
        "    Activation\n",
        "L8 - Max Pooling3\n",
        "L9 - Convolution5\n",
        "    Batch normalization\n",
        "    Activation\n",
        "L10 - Max Pooling4\n",
        "L11 - Flatten\n",
        "      Fully Connected\n",
        "\n",
        "We use catagorical cross-entropy for our loss function, and ADAM for our optimizer\n",
        "\"\"\"\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = 3, activation= \"relu\", input_shape = (master_sample.shape[1], master_sample.shape[2], 1), padding=\"valid\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(32, kernel_size = 3, padding=\"valid\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, kernel_size = 3, activation = \"relu\", padding=\"valid\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, kernel_size = 3, padding=\"valid\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, kernel_size = 3, padding=\"valid\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3))\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 118, 62, 64)       640       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 118, 62, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 116, 60, 32)       18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 116, 60, 32)       128       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 116, 60, 32)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 58, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 56, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 56, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 28, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 26, 12, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 26, 12, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 26, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 26, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 13, 6, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 11, 4, 32)         9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 11, 4, 32)         128       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 11, 4, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 5, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 963       \n",
            "=================================================================\n",
            "Total params: 48,195\n",
            "Trainable params: 48,003\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz_nUMoEG5_o",
        "outputId": "2f33b7f7-bc6e-4987-f8d4-eee5cfa504c7"
      },
      "source": [
        "model.fit(x_train_tensor, y_train_tensor, validation_data=(x_test_tensor, y_test_tensor), epochs=3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "16/16 [==============================] - 24s 1s/step - loss: 6.1511 - accuracy: 0.3136 - val_loss: 3.8202 - val_accuracy: 0.2344\n",
            "Epoch 2/3\n",
            "16/16 [==============================] - 23s 1s/step - loss: 3.0714 - accuracy: 0.3903 - val_loss: 8.1526 - val_accuracy: 0.2734\n",
            "Epoch 3/3\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.4581 - accuracy: 0.4523 - val_loss: 6.0554 - val_accuracy: 0.4688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6c43b17c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qct0uidMnf1i"
      },
      "source": [
        "Now that we've outlined our basic data flow, I begin my second interation below using MNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cezIa9FWcAZe"
      },
      "source": [
        "The code below downloads the data from the Physionet API using the MNE library. The function loads the files into a root directory, and the cell below moves them into a training directory.\n",
        "\n",
        "You will need to type \"y\" when running the function to confirm you want to download the files into the default path. It's easier to just use the default and move the files in the next cell then to define the preferred folder for each file download.\n",
        "\n",
        "Adjust the \"subjects\" and \"runs\" variables below to determine which subject/run combinations you'd like to download. Details are in the function docstring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-L7zy5FL6kD",
        "outputId": "b0a6deaf-7ee7-4759-bbe2-c5cce456ff68"
      },
      "source": [
        "subjects = [1,2,3,4,5]\n",
        "runs = [3,4,7,8,11,12]\n",
        "\n",
        "def download_physionet(subjects, runs):\n",
        "\n",
        "  \"\"\"\n",
        "  Takes an int or list of subjects, and downloads that subject's respective runs from the physionet EEG motor imagery dataset\n",
        "\n",
        "  PARAMETERS:\n",
        "  ---------------\n",
        "  subjects: int or list of ints to define which subjects to download. Values can range from 1-109 (inclusive)\n",
        "  runs: int or list of ints to define which runs to download for each subject. Values can range from 1-14 (inclusive)\n",
        "    run 1: Baseline (eyes open)\n",
        "    run 2: Baseline (eyes closed)\n",
        "    runs 3,7,11: Motor execution: left vs right hand\n",
        "    runs 4,8,12: Motor imagery: left vs right hand\n",
        "    runs 5,9,13: Motor execution: hands vs feet\n",
        "    runs 6,10,14: Motor imagery: hands vs feet\n",
        "\n",
        "  RETURNS:\n",
        "  ---------------\n",
        "    MNE raw object with all files concatonated\n",
        "  \"\"\"\n",
        "\n",
        "  raw_fnames = []\n",
        "\n",
        "  if type(subjects) == int:\n",
        "\n",
        "    try:\n",
        "      raw_fnames += eegbci.load_data(subjects, runs)\n",
        "\n",
        "    except HTTPError as err:\n",
        "      if err.code == 404:\n",
        "        print(\"Subject values must be 1-109 and run values must be 1-14\")\n",
        "        return\n",
        "      else:\n",
        "        raise\n",
        "\n",
        "  elif type(subjects) == list:\n",
        "\n",
        "    for subject in subjects:\n",
        "      try:\n",
        "        raw_fnames += eegbci.load_data(subject, runs)\n",
        "\n",
        "      except HTTPError as err:\n",
        "        if err.code == 404:\n",
        "          print(\"Subject values must be 1-109 and run values must be 1-14\")\n",
        "          return\n",
        "        else:\n",
        "          raise\n",
        "\n",
        "  else:\n",
        "    print(\"Subjects parameter must be int or list\")\n",
        "\n",
        "\n",
        "  raws = [read_raw_edf(f, preload=True) for f in raw_fnames]\n",
        "  raw = concatenate_raws(raws)\n",
        "\n",
        "  return\n",
        "\n",
        "download_physionet(subjects, runs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading EEGBCI data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'S001/S001R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R03.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S001/S001R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S001/S001R07.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R07.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S001/S001R08.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R08.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S001/S001R11.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R11.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S001/S001R12.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R12.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete in 17s (14.9 MB)\n",
            "Downloading EEGBCI data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'S002/S002R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R03.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S002/S002R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R04.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S002/S002R07.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R07.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S002/S002R08.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R08.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S002/S002R11.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R11.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S002/S002R12.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R12.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete in 17s (14.6 MB)\n",
            "Downloading EEGBCI data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'S003/S003R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R03.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S003/S003R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R04.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S003/S003R07.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R07.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S003/S003R08.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R08.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S003/S003R11.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R11.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S003/S003R12.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R12.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete in 17s (14.9 MB)\n",
            "Downloading EEGBCI data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'S004/S004R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R03.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S004/S004R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R04.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S004/S004R07.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R07.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S004/S004R08.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R08.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S004/S004R11.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R11.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S004/S004R12.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R12.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete in 16s (14.6 MB)\n",
            "Downloading EEGBCI data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'S005/S005R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R03.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S005/S005R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R04.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S005/S005R07.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R07.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S005/S005R08.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R08.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S005/S005R11.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R11.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
            "Downloading file 'S005/S005R12.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R12.edf' to '/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete in 18s (14.6 MB)\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S002/S002R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S003/S003R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S004/S004R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S005/S005R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S005/S005R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S005/S005R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S005/S005R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S005/S005R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n",
            "Extracting EDF parameters from /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S005/S005R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19679  =      0.000 ...   122.994 secs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRsGnUcOdCSd"
      },
      "source": [
        "Moves files to training directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q2pli1NcaEF"
      },
      "source": [
        "os.mkdir(\"/content/train\")\n",
        "\n",
        "for i, foldername in enumerate(os.listdir(\"/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0\")):\n",
        "  for j, filename in enumerate(os.listdir(\"/root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/\"+ foldername)):\n",
        "    os.system(\"mv /root/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/\" + foldername + \"/\" + filename + \" /content/train\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYy_nm1kKkNd"
      },
      "source": [
        "Next we need to combine the signal and annotations into a master like we did before using PyEDFlib. This is currently my TODO, so the code below is incomplete, and largely a set of experimental code blocks.\n",
        "\n",
        "However, if you continue scrolling you can find some basic ML models I created out of curiousity, as well as some very basic exploratory analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "8xhdCZYeX5G7",
        "outputId": "d537c1cb-beee-4681-8e08-275e88c2919d"
      },
      "source": [
        "eegbci.standardize(raw)\n",
        "montage = make_standard_montage('standard_1005')\n",
        "raw.set_montage(montage)\n",
        "\n",
        "raw.rename_channels(lambda x: x.strip('.'))\n",
        "\n",
        "events, _ = events_from_annotations(raw, event_id=dict(T1=2, T2=3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-140b9f0c1aa3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meegbci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmontage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_standard_montage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'standard_1005'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_montage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmontage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Oy2YfSb_me",
        "outputId": "a1ca5a53-fde9-495a-8a4a-57ae2e8112e9"
      },
      "source": [
        "data = raw.get_data()\n",
        "type(data)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 594240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKYVo7aVP6jZ",
        "outputId": "4562c84e-47b4-4871-a5a6-f4e7c2be9668"
      },
      "source": [
        "len(events)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "450"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UfKeL4uf3o1",
        "outputId": "675d3b4b-9cbe-4e75-9147-1da7d82e3f4e"
      },
      "source": [
        "test_mne = read_raw_edf(\"/content/train/S001R03.edf\", preload=True)\n",
        "test_mne.get_data().shape\n",
        "data = test_mne.get_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from /content/train/S001R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Ub-66peIeB"
      },
      "source": [
        "test = pyedflib.EdfReader(\"/content/sample_data/S001R03.edf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsmQAel2lF4-"
      },
      "source": [
        "# n = test.signals_in_file\n",
        "# signal_labels = test.getSignalLabels()\n",
        "# sigbufs = np.zeros((n, test.getNSamples()[0]))\n",
        "# for i in np.arange(n):\n",
        "#     sigbufs[i, :] = test.readSignal(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dgFST_uI0jC"
      },
      "source": [
        "numSignals = test.signals_in_file\n",
        "\n",
        "dataset = np.zeros((numSignals, test.getNSamples()[0]))\n",
        "\n",
        "# creates array of (signal_source, signal) i.e. (node 64, signal of that node)\n",
        "# Then removes trailing 0 values\n",
        "for signal in np.arange(numSignals):\n",
        "    dataset[signal, :] = test.readSignal(signal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql9NRHiyeU5S",
        "outputId": "d0118fd6-e7d9-4f42-a781-3214cc72875d"
      },
      "source": [
        "dataset.shape == data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Fsbj3hgSm5",
        "outputId": "5ada5a37-06e2-4e21-e98d-93ba8f3534af"
      },
      "source": [
        "annotations = test.readAnnotations()\n",
        "annotations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0. ,   4.2,   8.3,  12.5,  16.6,  20.8,  24.9,  29.1,  33.2,\n",
              "         37.4,  41.5,  45.7,  49.8,  54. ,  58.1,  62.3,  66.4,  70.6,\n",
              "         74.7,  78.9,  83. ,  87.2,  91.3,  95.5,  99.6, 103.8, 107.9,\n",
              "        112.1, 116.2, 120.4]),\n",
              " array([4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2,\n",
              "        4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1, 4.2, 4.1,\n",
              "        4.2, 4.1, 4.2, 4.1]),\n",
              " array(['T0', 'T2', 'T0', 'T1', 'T0', 'T1', 'T0', 'T2', 'T0', 'T2', 'T0',\n",
              "        'T1', 'T0', 'T1', 'T0', 'T2', 'T0', 'T1', 'T0', 'T2', 'T0', 'T2',\n",
              "        'T0', 'T1', 'T0', 'T1', 'T0', 'T2', 'T0', 'T1'], dtype='<U2'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh526h-1euqf"
      },
      "source": [
        "[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH5U-ycmWWyU"
      },
      "source": [
        "def create_master(edf, signal_length, time_length):\n",
        "\n",
        "   \"\"\"\n",
        "    Takes in an edf file and returns the dataset, as well as a master set\n",
        "\n",
        "    Assumes file is a standard 64 signal edf\n",
        "\n",
        "    removes last half second of file (which is 0 for my dataset)\n",
        "\n",
        "    This is designed for two-minute recordings. The function will currently not work properly if time_length is not set to 120. This is a TODO.\n",
        "\n",
        "    INPUT\n",
        "    edf: an edf file read in with pyedflib.EdfReader()\n",
        "    signal_length: length of signal (how many datapoints in each signal)\n",
        "    time_length: length of experiment in seconds\n",
        "\n",
        "    RETURNS\n",
        "    dataset: ndarray (signal_length x #_signals), represents the signal for each node\n",
        "    master_df: pandas dataframe (signal_length x (2 + #_signals)), with timestamp and annotation as first two columns\n",
        "\n",
        "    \"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrJlDME04Hg8",
        "outputId": "97f68287-9263-45c7-baf8-855843a101a9"
      },
      "source": [
        "samples.shape()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 160, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9_ELJ2tOQhN",
        "outputId": "58654c9c-6272-49ec-ab6a-3b5b14f88717"
      },
      "source": [
        "master_sample.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640, 120, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoECZuEfKu7f"
      },
      "source": [
        "Here, we do some traditional machine learning algorithms (SVM and Logistic regression to start) and check their accuracy and speed to compare to our CNN.\n",
        "\n",
        "However, these don't use the sampled data as discussed, and were really more for my own curiosity/exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FxCjYUy7bvZc"
      },
      "source": [
        "traditional_labels = master_df[\"label\"]\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(dataset, traditional_labels,\n",
        "                                               train_size = 0.8,\n",
        "                                               test_size = 0.2,\n",
        "                                               random_state = 24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nDwJbVlyahFd"
      },
      "source": [
        "svm_classifier = svm.SVC()\n",
        "svm_classifier.fit(x_train, y_train)\n",
        "\n",
        "svm_pred = svm_classifier.predict(x_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test,svm_pred) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZymlzmOpbVql"
      },
      "source": [
        "# takes a single row from the test set and times it\n",
        "sample = x_test[0].reshape(1,-1)\n",
        "%timeit svm_classifier.predict(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CjmVAHISgafc"
      },
      "source": [
        "log_classifier = LogisticRegression()\n",
        "log_classifier.fit(x_train,y_train)\n",
        "\n",
        "log_pred = log_classifier.predict(x_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, log_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IplGQZKNlC_i"
      },
      "source": [
        "%timeit log_classifier.predict(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH-a9a9HK8UX"
      },
      "source": [
        "Here we begin to build our CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_R_irqGn1aU"
      },
      "source": [
        "This was some code I wrote while I considered using a 3d CNN. However, I found it would make real-time processing slow, was unnecessarily complicated, and decided against using it. I've kept the code in case I change my mind one day, or want to explore it further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF0kuWVtrn1J"
      },
      "source": [
        "\"\"\"\n",
        "This was an attempt to reshape the signal into a 4d tensor using 3 of the\n",
        "dimensions as input for the CNN, but I realized that doing that transformation\n",
        "would make real time processing slow.\n",
        "\n",
        "It is also incorrect as related to the research article I read. The re-shaping\n",
        "is not as needed.\n",
        "\n",
        "# Do this num_indicies times and stack\n",
        "frame1 = dataset3[0:8,:]\n",
        "frame2 = dataset3[1:9,:]\n",
        "frame3 = dataset3[2:10,:]\n",
        "frame4 = dataset3[3:11,:]\n",
        "frame5 = dataset3[4:12,:]\n",
        "frame6 = dataset3[5:13,:]\n",
        "\n",
        "c = np.stack((frame1, frame2, frame3, frame4, frame5, frame6))\n",
        "# c = c.reshape(8,64,6)\n",
        "print(dataset3.shape[0])\n",
        "\"\"\"\n",
        "\n",
        "def create_3D(dataset, frame_size, chunk_size):\n",
        "\n",
        "  \"\"\"\n",
        "  INPUT\n",
        "  dataset: an EEG dataset of type array and shape (time_stamp x number of channels)\n",
        "  chunk_size: number of frames pooled together to create a chunk i.e. depth of output tensor\n",
        "  frame_size: number of timestamps pooled together to create a frame i.e. width of output tensor\n",
        "\n",
        "  The height of the output tensor is the number of channels i.e. dataset.shape[1]\n",
        "\n",
        "  OUTPUT\n",
        "\n",
        "  tensor: A 4d tensor of shape (index, frame_size, num_channels, chunk_size).\n",
        "\n",
        "  each index is the 3d tensor used as input for the CNN\n",
        "\n",
        "\n",
        "  In my case, I'll use a frame size of 8 and a chunk size of 6\n",
        "  \"\"\"\n",
        "\n",
        "  num_indices = dataset.size / dataset.shape[1] / frame_size / chunk_size\n",
        "\n",
        "  if num_indices.is_integer():\n",
        "    num_indices = int(num_indices)\n",
        "\n",
        "  else:\n",
        "    print(\"Proposed chunk and/or frame size do not fit data\")\n",
        "    return\n",
        "\n",
        "  try:\n",
        "\n",
        "    return np.reshape(dataset, (num_indices, frame_size, dataset.shape[1], chunk_size), order = \"F\")\n",
        "\n",
        "  except ValueError:\n",
        "\n",
        "    print(\"Proposed chunk and/or frame size do not fit data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxl3lQaXoPsj"
      },
      "source": [
        "This was a brief analysis of the \"moments\" in the data, which are the events. I wanted to see if the events really did have higher mean values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUfp3CyA6gKJ",
        "outputId": "261358c2-c62c-47cc-8595-809f46e5910b"
      },
      "source": [
        "moments = master_df[master_df[\"label\"] == \"T1\"]\n",
        "moments.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5248, 66)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Yn6rgXLLwd0n",
        "outputId": "ea6c80ed-b077-4eac-a59b-c3ef6ea0d933"
      },
      "source": [
        "moment_data = moments.iloc[:,2:]\n",
        "moment_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c1</th>\n",
              "      <th>c2</th>\n",
              "      <th>c3</th>\n",
              "      <th>c4</th>\n",
              "      <th>c5</th>\n",
              "      <th>c6</th>\n",
              "      <th>c7</th>\n",
              "      <th>c8</th>\n",
              "      <th>c9</th>\n",
              "      <th>c10</th>\n",
              "      <th>c11</th>\n",
              "      <th>c12</th>\n",
              "      <th>c13</th>\n",
              "      <th>c14</th>\n",
              "      <th>c15</th>\n",
              "      <th>c16</th>\n",
              "      <th>c17</th>\n",
              "      <th>c18</th>\n",
              "      <th>c19</th>\n",
              "      <th>c20</th>\n",
              "      <th>c21</th>\n",
              "      <th>c22</th>\n",
              "      <th>c23</th>\n",
              "      <th>c24</th>\n",
              "      <th>c25</th>\n",
              "      <th>c26</th>\n",
              "      <th>c27</th>\n",
              "      <th>c28</th>\n",
              "      <th>c29</th>\n",
              "      <th>c30</th>\n",
              "      <th>c31</th>\n",
              "      <th>c32</th>\n",
              "      <th>c33</th>\n",
              "      <th>c34</th>\n",
              "      <th>c35</th>\n",
              "      <th>c36</th>\n",
              "      <th>c37</th>\n",
              "      <th>c38</th>\n",
              "      <th>c39</th>\n",
              "      <th>c40</th>\n",
              "      <th>c41</th>\n",
              "      <th>c42</th>\n",
              "      <th>c43</th>\n",
              "      <th>c44</th>\n",
              "      <th>c45</th>\n",
              "      <th>c46</th>\n",
              "      <th>c47</th>\n",
              "      <th>c48</th>\n",
              "      <th>c49</th>\n",
              "      <th>c50</th>\n",
              "      <th>c51</th>\n",
              "      <th>c52</th>\n",
              "      <th>c53</th>\n",
              "      <th>c54</th>\n",
              "      <th>c56</th>\n",
              "      <th>c57</th>\n",
              "      <th>c58</th>\n",
              "      <th>c59</th>\n",
              "      <th>c60</th>\n",
              "      <th>c61</th>\n",
              "      <th>c62</th>\n",
              "      <th>c63</th>\n",
              "      <th>c64</th>\n",
              "      <th>c65</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>-11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>-50.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-55.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>-51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>-31.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>-48.0</td>\n",
              "      <td>-83.0</td>\n",
              "      <td>-78.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>-36.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-50.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-54.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-52.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-30.0</td>\n",
              "      <td>-28.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>-49.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-29.0</td>\n",
              "      <td>-28.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-64.0</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-86.0</td>\n",
              "      <td>-80.0</td>\n",
              "      <td>-29.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>-78.0</td>\n",
              "      <td>-54.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-59.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>-29.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-56.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-24.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>-42.0</td>\n",
              "      <td>-37.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>-35.0</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>-78.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-53.0</td>\n",
              "      <td>-38.0</td>\n",
              "      <td>-28.0</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-62.0</td>\n",
              "      <td>-49.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-68.0</td>\n",
              "      <td>-59.0</td>\n",
              "      <td>-48.0</td>\n",
              "      <td>-42.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-90.0</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>-51.0</td>\n",
              "      <td>-113.0</td>\n",
              "      <td>-106.0</td>\n",
              "      <td>-49.0</td>\n",
              "      <td>-30.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>-108.0</td>\n",
              "      <td>-68.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>-66.0</td>\n",
              "      <td>-65.0</td>\n",
              "      <td>-41.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>-90.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-56.0</td>\n",
              "      <td>-42.0</td>\n",
              "      <td>-85.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-58.0</td>\n",
              "      <td>-57.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-54.0</td>\n",
              "      <td>-38.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>-50.0</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>-81.0</td>\n",
              "      <td>-67.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-44.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-50.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>-51.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-68.0</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-42.0</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-79.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>-90.0</td>\n",
              "      <td>-87.0</td>\n",
              "      <td>-40.0</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-95.0</td>\n",
              "      <td>-49.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-47.0</td>\n",
              "      <td>-51.0</td>\n",
              "      <td>-53.0</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-69.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-64.0</td>\n",
              "      <td>-45.0</td>\n",
              "      <td>-84.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>-54.0</td>\n",
              "      <td>-50.0</td>\n",
              "      <td>-48.0</td>\n",
              "      <td>-42.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>-24.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>-44.0</td>\n",
              "      <td>-35.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-37.0</td>\n",
              "      <td>-28.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19915</th>\n",
              "      <td>23.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19916</th>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19917</th>\n",
              "      <td>23.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>-30.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19918</th>\n",
              "      <td>38.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19919</th>\n",
              "      <td>50.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-16.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5248 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          c1     c2     c3     c4     c5  ...    c61    c62    c63    c64    c65\n",
              "2000   -11.0   10.0   16.0   22.0   28.0  ...  -16.0   -8.0  -21.0  -21.0  -51.0\n",
              "2001   -31.0   -8.0   -5.0   -2.0    5.0  ...   -9.0   -9.0  -16.0  -20.0  -48.0\n",
              "2002   -49.0  -26.0  -21.0  -15.0   -6.0  ...  -15.0  -20.0  -22.0  -16.0  -43.0\n",
              "2003   -78.0  -61.0  -53.0  -38.0  -28.0  ...  -20.0  -33.0  -34.0  -10.0  -42.0\n",
              "2004   -81.0  -67.0  -61.0  -44.0  -33.0  ...  -14.0  -37.0  -28.0    6.0  -23.0\n",
              "...      ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "19915   23.0   16.0   14.0   10.0   10.0  ...   46.0   76.0   68.0   86.0   32.0\n",
              "19916   23.0   23.0   24.0   20.0   23.0  ...   79.0   72.0   82.0  124.0   51.0\n",
              "19917   23.0   14.0   11.0    3.0    5.0  ...   85.0   62.0   97.0  156.0   75.0\n",
              "19918   38.0   27.0   28.0   19.0   19.0  ...   43.0   44.0   81.0  140.0   66.0\n",
              "19919   50.0   35.0   41.0   40.0   33.0  ...   -4.0   12.0   32.0   78.0   16.0\n",
              "\n",
              "[5248 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhXLrL9Ow1Ep",
        "outputId": "a44b70f9-82a0-4ee4-e8ec-6bff04e33b5d"
      },
      "source": [
        "print(moment_data.astype(float).stack().mean())\n",
        "print(moment_data.astype(float).stack().std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.5217434022484757\n",
            "69.9608073016054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUZ84i3JxhM3",
        "outputId": "bf6466e4-2aa8-48c2-8b68-090438d52eee"
      },
      "source": [
        "rest_data = master_df[master_df[\"label\"] == \"T0\"].iloc[:,2:]\n",
        "rest_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10080, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyCYTxmo0j9Y",
        "outputId": "3d102662-f8f6-4619-ddb0-d5823b2ebe80"
      },
      "source": [
        "print(rest_data.astype(float).stack().mean())\n",
        "print(rest_data.astype(float).stack().std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-6.537375992063492\n",
            "62.031341693062885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3dxOSRmobc6"
      },
      "source": [
        "Seems like the moments really do have higher means. I obviously haven't done any hypothesis tests or anything, but a quick glance shows that we're probably on to something."
      ]
    }
  ]
}